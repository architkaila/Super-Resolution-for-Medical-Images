{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b61b1-9f58-45aa-858c-4daaf34ad772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import sys\n",
    "\n",
    "## Add the scripts folder to the path\n",
    "sys.path.insert(0, '../scripts/')\n",
    "from model_architecture import Generator\n",
    "\n",
    "## Set the seed for reproducibility\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697c415-5c76-4f65-ab20-b1f0fe3b52f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set the device\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "## Load the model\n",
    "model = Generator(upscale_factor=4).to(DEVICE)\n",
    "\n",
    "## Load the model weights state dict\n",
    "state_dict = torch.load('../models/netG_4x_epoch5.pth.tar', map_location=torch.device(DEVICE))\n",
    "\n",
    "## Load the model from state dict\n",
    "model.load_state_dict(state_dict[\"model\"], )\n",
    "\n",
    "## Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec707d24-d896-4874-bb6f-b12122b173c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "hr_image = Image.open('../assets/sample_hr_input.png').convert('RGB')\n",
    "\n",
    "## Create the LR image transformer by downsampling the HR image and applying bicubic interpolation\n",
    "lr_scale = transforms.Resize((256,256), interpolation=Image.BICUBIC)\n",
    "\n",
    "## Create the restored HR image tranformer (simple classical method) by upsampling the LR image and applying bicubic interpolation\n",
    "hr_scale = transforms.Resize((1024,1024), interpolation=Image.BICUBIC)\n",
    "\n",
    "## Create the LR Image from the original HR Image using the LR Image transformer\n",
    "lr_image = lr_scale(hr_image)\n",
    "lr_image.save(\"../assets/sample_lr_input.png\")\n",
    "\n",
    "## Create the restored HR Image from the LR Image using the classical method of restored HR Image transforms\n",
    "hr_restore_img = hr_scale(lr_image)\n",
    "\n",
    "## Convert the LR Image to a tensor\n",
    "lr_image = to_tensor(lr_image)\n",
    "\n",
    "# Move the image and model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    lr_image = lr_image.cuda()\n",
    "\n",
    "## Add a batch dimension to the image\n",
    "lr_image = lr_image.unsqueeze(0)\n",
    "\n",
    "lr_image.shape\n",
    "\n",
    "# Perform model inference\n",
    "with torch.no_grad():\n",
    "    output = model(lr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93a17d-fce7-4a7e-9624-732cf138fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the batch dimension\n",
    "out = output.squeeze(0)\n",
    "\n",
    "## Transforms for displaying the images\n",
    "display_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "## Transform the output image\n",
    "out = display_transform(out)\n",
    "\n",
    "## Save the output image\n",
    "out.save(\"../assets/sample_sr_output.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipi540_individual",
   "language": "python",
   "name": "aipi540_individual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
