{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b61b1-9f58-45aa-858c-4daaf34ad772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from data import TrainDataset, ValDataset, display_transform\n",
    "from torch.utils.data import DataLoader\n",
    "from models import Generator, Discriminator\n",
    "from loss import GeneratorLoss\n",
    "from metric import ssim\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "## Set the seed for reproducibility\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20de99-23cf-43cd-8009-6e9303940558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize parameters\n",
    "CROP_SIZE = 100\n",
    "UPSCALE_FACTOR = 4\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e731f-9b72-4cb6-bbea-e39e462966a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the generator\n",
    "netG = Generator(upscale_factor=4).to(DEVICE)\n",
    "print(\"# generator parameters:\", sum(param.numel() for param in netG.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126a0e6-80a2-45b2-94ab-6b6aa12de425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the discriminator\n",
    "netD = Discriminator().to(DEVICE)\n",
    "print(\"# discriminator parameters:\", sum(param.numel() for param in netD.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c535abf-207d-4f84-b0b7-7d49f7be0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the loss function\n",
    "generator_criterion = GeneratorLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61e68b-66a6-4d9d-9e8a-45594030e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the optimizer\n",
    "optimizerG = torch.optim.AdamW(netG.parameters(), lr=1e-3)\n",
    "optimizerD = torch.optim.AdamW(netD.parameters(), lr=1e-3)\n",
    "\n",
    "## Initialize the dictionary to store the results\n",
    "results = {\n",
    "    \"d_loss\": [],\n",
    "    \"g_loss\": [],\n",
    "    \"d_score\": [],\n",
    "    \"g_score\": [],\n",
    "    \"psnr\": [],\n",
    "    \"ssim\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cf190-b557-4cf8-bef8-e0839ed15581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the train dataset\n",
    "print(\"[INFO] Loading Train dataset\")\n",
    "train_set = TrainDataset(\"../dataset/train\", crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
    "\n",
    "## Load the validation dataset\n",
    "print(\"[INFO] Loading Val dataset\")\n",
    "val_set = ValDataset(\"../dataset/valid\", crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4ac0f-d152-44da-86b5-a6ea7a9e9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the train data loader\n",
    "print(\"[INFO] Creating Train data loader\")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "## Create the validation data loader\n",
    "print(\"[INFO] Creating Val data loader\")\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79c586-390e-49b0-a28a-124547cc113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start training\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "\n",
    "    ## Progress bar for training\n",
    "    train_bar = tqdm(train_loader, total=len(train_loader))\n",
    "\n",
    "    ## Initialize the dictionary to store the results\n",
    "    running_results = {\"batch_sizes\": 0, \n",
    "                       \"d_loss\": 0, \"g_loss\": 0,\n",
    "                       \"d_score\": 0, \"g_score\": 0,\n",
    "                    }\n",
    "\n",
    "    ## Set the models to train mode\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "\n",
    "    ## Iterate over the batch of images\n",
    "    for lr_img, hr_img in train_bar:\n",
    "\n",
    "        ## Get the current batch size\n",
    "        batch_size = lr_img.size(0)\n",
    "        running_results[\"batch_sizes\"] += batch_size\n",
    "\n",
    "        ## Move the images to the GPU\n",
    "        hr_img = hr_img.to(DEVICE) # high resolution image\n",
    "        lr_img = lr_img.to(DEVICE) # low resolution image\n",
    "        with torch.no_grad():\n",
    "            sr_img = netG(lr_img) # super resolution image\n",
    "\n",
    "        ## Set the gradients of Discriminator to zero\n",
    "        netD.zero_grad()\n",
    "\n",
    "        ## Formward propagate the HR image and SR image through the discriminator\n",
    "        real_out = netD(hr_img).mean()\n",
    "        fake_out = netD(sr_img).mean()\n",
    "\n",
    "        ## Calculate the discriminator loss\n",
    "        d_loss = 1 - real_out + fake_out\n",
    "\n",
    "        ## Backpropagate the loss\n",
    "        d_loss.backward(retain_graph=True)\n",
    "\n",
    "        ## Update the weights\n",
    "        optimizerD.step()\n",
    "        \n",
    "        ## Forward propagate the SR image through the discriminator\n",
    "        with torch.no_grad():\n",
    "            fake_out = netD(sr_img).mean()\n",
    "        \n",
    "        ## Set the gradients of the Generator to zero\n",
    "        netG.zero_grad()\n",
    "\n",
    "        ## Forward propagate the LR image through the generator to get the SR image\n",
    "        sr_img = netG(lr_img)\n",
    "\n",
    "        ## Calculate the generator loss\n",
    "        g_loss = generator_criterion(fake_out, sr_img, hr_img)\n",
    "\n",
    "        ## Backpropagate the loss\n",
    "        g_loss.backward()\n",
    "\n",
    "        ## Update the weights\n",
    "        optimizerG.step()\n",
    "\n",
    "        ## Store loss for current batch\n",
    "        running_results[\"g_loss\"] += g_loss.item() * batch_size\n",
    "        running_results[\"d_loss\"] += d_loss.item() * batch_size\n",
    "        running_results[\"d_score\"] += real_out.item() * batch_size\n",
    "        running_results[\"g_score\"] += fake_out.item() * batch_size\n",
    "\n",
    "        ## Update the progress bar and print the results\n",
    "        train_bar.set_description(\n",
    "            desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f\"\n",
    "            % (\n",
    "                epoch,\n",
    "                NUM_EPOCHS,\n",
    "                running_results[\"d_loss\"] / running_results[\"batch_sizes\"],\n",
    "                running_results[\"g_loss\"] / running_results[\"batch_sizes\"],\n",
    "                running_results[\"d_score\"] / running_results[\"batch_sizes\"],\n",
    "                running_results[\"g_score\"] / running_results[\"batch_sizes\"],\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ## Set the Generator to evaluation mode\n",
    "    netG.eval()\n",
    "\n",
    "    ## Run the validation loop\n",
    "    with torch.no_grad():\n",
    "\n",
    "        ## Progress bar for validation loop\n",
    "        val_bar = tqdm(val_loader, total=len(val_loader))\n",
    "\n",
    "        ## Initialize the dictionary to store the results\n",
    "        valing_results = {\n",
    "            \"mse\": 0,\n",
    "            \"ssims\": 0,\n",
    "            \"psnr\": 0,\n",
    "            \"ssim\": 0,\n",
    "            \"batch_sizes\": 0,\n",
    "        }\n",
    "\n",
    "        val_images = []\n",
    "\n",
    "        ## Iterate over the batch of images\n",
    "        for val_lr, val_hr_restore, val_hr in val_bar:\n",
    "\n",
    "            ## Get the current batch size\n",
    "            batch_size = val_lr.size(0)\n",
    "            valing_results[\"batch_sizes\"] += batch_size\n",
    "\n",
    "            ## Move the images to the GPU\n",
    "            lr = val_lr\n",
    "            hr = val_hr\n",
    "            if torch.cuda.is_available():\n",
    "                lr = lr.cuda()\n",
    "                hr = hr.cuda()\n",
    "\n",
    "            ## Forward propagate the LR image through the generator to get the SR image\n",
    "            sr = netG(lr)\n",
    "\n",
    "            ## Calculate All the metrics\n",
    "            ## Calculate and store the MSE\n",
    "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
    "            valing_results[\"mse\"] += batch_mse * batch_size\n",
    "\n",
    "            ## Calculate and store the SSIMs\n",
    "            batch_ssim = ssim(sr, hr).item()\n",
    "            valing_results[\"ssims\"] += batch_ssim * batch_size\n",
    "\n",
    "            ## Calculate and store the PSNR\n",
    "            valing_results[\"psnr\"] = 10 * math.log10( (hr.max() ** 2) / (valing_results[\"mse\"] / valing_results[\"batch_sizes\"]))\n",
    "\n",
    "            ## Calculate and store the SSIM\n",
    "            valing_results[\"ssim\"] = (valing_results[\"ssims\"] / valing_results[\"batch_sizes\"])\n",
    "\n",
    "            ## Update the progress bar and print the results\n",
    "            val_bar.set_description(\n",
    "                desc=\"[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f\"\n",
    "                % (valing_results[\"psnr\"], valing_results[\"ssim\"])\n",
    "            )\n",
    "\n",
    "    ## save model parameters every epoch\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "\n",
    "    ## Save the Generator model\n",
    "    torch.save({\"model\": netG.state_dict()},\n",
    "        f\"./checkpoints/netG_{UPSCALE_FACTOR}x_epoch{epoch}.pth.tar\")\n",
    "\n",
    "    ## Save the Discriminator model\n",
    "    torch.save({\"model\": netD.state_dict()},\n",
    "        f\"./checkpoints/netD_{UPSCALE_FACTOR}x_epoch{epoch}.pth.tar\")\n",
    "\n",
    "    ## Store the losses and scores for the current epoch\n",
    "    results[\"d_loss\"].append(running_results[\"d_loss\"] / running_results[\"batch_sizes\"])\n",
    "    results[\"g_loss\"].append(running_results[\"g_loss\"] / running_results[\"batch_sizes\"])\n",
    "    results[\"d_score\"].append(running_results[\"d_score\"] / running_results[\"batch_sizes\"])\n",
    "    results[\"g_score\"].append(running_results[\"g_score\"] / running_results[\"batch_sizes\"])\n",
    "    results[\"psnr\"].append(valing_results[\"psnr\"])\n",
    "    results[\"ssim\"].append(valing_results[\"ssim\"])\n",
    "\n",
    "    ## Save the results every 10 epochs\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        out_path = \"./logs/\"\n",
    "        data_frame = pd.DataFrame(\n",
    "            data={\n",
    "                \"Loss_D\": results[\"d_loss\"],\n",
    "                \"Loss_G\": results[\"g_loss\"],\n",
    "                \"Score_D\": results[\"d_score\"],\n",
    "                \"Score_G\": results[\"g_score\"],\n",
    "                \"PSNR\": results[\"psnr\"],\n",
    "                \"SSIM\": results[\"ssim\"],\n",
    "            },\n",
    "            index=range(1, epoch + 1),\n",
    "        )\n",
    "\n",
    "        ## Save the results to the disk\n",
    "        data_frame.to_csv(\n",
    "            out_path + \"ssrgan_\" + str(UPSCALE_FACTOR) + \"_train_results.csv\",\n",
    "            index_label=\"Epoch\",\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a70a7-d259-4e52-9b31-c9e1f6c8000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the memory usage of the image tensor\n",
    "total_memory_bytes = lr.element_size() * lr.nelement()\n",
    "print(f\"Total memory usage of the tensor: {total_memory_bytes/1e+9} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e456a5-b7e8-4b77-b078-e1f59134521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the summary of the memory usage\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e39ab9-9d6d-447d-8850-386053b1e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the memory allocated to the image tensor\n",
    "torch.cuda.memory_allocated(hr_img)/1e+9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipi_ind_project",
   "language": "python",
   "name": "aipi_ind_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
